<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>Information, Inference and Machine Learning Group at University College London</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="css/business-frontpage.css" rel="stylesheet">

  <script src="https://kit.fontawesome.com/f071da7bc5.js"></script>

  <link rel='icon' href='imgs/favicon.ico' type='image/x-icon' sizes="16x16" />



  <script src="https://code.jquery.com/jquery-3.3.1.js" integrity="sha256-2Kok7MbOyxpgUVvAk/HJ2jigOSYS2auK4Pfzbm7uH60="
    crossorigin="anonymous">
  </script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

</head>

<script>
  $(function () {
    $("#footer").load("footer.html");
  });
</script>

<body>

  <!-- Navigation -->
  <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
    <div class="container">
      <a class="navbar-brand" href="index.html">I<sup>2</sup>|ML at UCL</a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive"
        aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a class="nav-link" href="index.html">Home
            </a>
          </li>
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" href="members/members.html" id="navbarDropdownMenuLink"
              data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
              Members
            </a>
            <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
              <a class="dropdown-item" href="members/members.html#principal-investigator">Head of Lab</a>
              <a class="dropdown-item" href="members/members.html#postdocs">Postdocs</a>
              <a class="dropdown-item" href="members/members.html#phds">PhD Students</a>
              <a class="dropdown-item" href="members/members.html#alumni">Alumni</a>
            </div>
          </li>
            <li class="nav-item">
              <a class="nav-link" href="projects/projects.html">Projects</a>
            </li>
          <li class="nav-item dropdown">
            <a class="nav-link active dropdown-toggle" href="publications.html" id="navbarDropdownMenuLink"
              data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
              Publications
            </a>
            <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
              <a class="dropdown-item" href="publications.html#2020">2020</a>
              <a class="dropdown-item" href="publications.html#2019">2019</a>
              <a class="dropdown-item" href="publications.html#2018">2018</a>
              <a class="dropdown-item" href="publications.html#2017">2017</a>
              <a class="dropdown-item" href="publications.html#2016">2016</a>
              <a class="dropdown-item" href="publications.html#Older">Older</a>
            </div>
          </li>
          <li class="nav-item">
            <a class="nav-link" target="_blank" href="https://github.com/iiml-ucl">Software</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="press.html">Press</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="openings.html">Openings</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="location.html">Location</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  <!-- Header -->
  <header class="bg-primary py-5 mb-5">
    <div class="container h-50">
      <div class="row h-100 align-items-center">
        <div class="col-lg-12">
          <h1 class="display-4 text-white mt-2 mb-2">Publications</h1>
        </div>
      </div>
    </div>
  </header>

  <!-- Page Content -->
  <div class="container">
    <div class="row">
      <div id="sidebar-container" class="sidebar-expanded col- d-1 d-md-block" style="position:sticky;">
        <ul class="nobull list-group sticky-top sticky-offset">
          <li class="nav-item">
            <a class="nav-link" href="#2020">
              <h4>2020</h4>
            </a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="#2019">
              <h4>2019</h4>
            </a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="#2018">
              <h4>2018</h4>
            </a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="#2017">
              <h4>2017</h4>
            </a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="#2016">
              <h4>2016</h4>
            </a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="#older">
              <h4>Older</h4>
            </a>
          </li>
        </ul>
      </div>
      <div class="col offset-1" id="main">
        <div class="row">
          <div id="2020" class="col-md-12 mb-5">
            <h2>2020</h2>
            <hr>
          </div>
        </div>
        <div class="row">
          <div class="col-md-12">
            <div id="mrd2020" class="row publication">
              <div class="col-md-4">
                <a href="https://www.amazon.com/Information-Theoretic-Methods-Science-Miguel-Rodrigues/dp/1108427138"
                  target="_blank"><img class="img-fluid" src="publications/2020/mrd2020.jpg" alt=""></a>
              </div>
              <div class="col-md-8 publication-text">
                <strong>Title:</strong> Information-Theoretic Methods in Data Science<br>
                <strong>Authors:</strong> Rodrigues, M. R. D. and Eldar, Y. C.<br>
                <strong>Journal/Conference:</strong> Cambridge University Press<br>
                <p> <strong>Abstract:</strong> Learn about the state-of-the-art at the interface between information
                  theory and data science with
                  this first unified treatment of the subject. Written by leading experts in a clear, tutorial style,
                  and using consistent notation and definitions throughout, it shows how information-theoretic methods
                  are being used in data acquisition, data representation, data analysis, and statistics and machine
                  learning. Coverage is broad, with chapters on signal acquisition, data compression, compressive
                  sensing, data communication, representation learning, emerging topics in statistics, and much more.
                  Each chapter includes a topic overview, definition of the key problems, emerging and open problems,
                  and an extensive reference list, allowing readers to develop in-depth knowledge and understanding.
                  Providing a thorough survey of the current research area and cutting-edge trends, this is essential
                  reading for graduate students and researchers working in information theory, signal processing,
                  machine learning, and statistics.</p>
                <a href="https://www.amazon.com/Information-Theoretic-Methods-Science-Miguel-Rodrigues/dp/1108427138"
                  target="_blank"><strong><i class="fas fa-link"></i> Link</strong></a>
              </div>
            </div>
          </div>
        </div>
        <div class="row">
          <div id="2019" class="col-md-12 mb-5" style="padding-top: 20px">
            <h2>2019</h2>
            <hr>
          </div>
        </div>
        <div class="row">
          <div class="col-md-12">
            <div id="z2019sci" class="row publication">
              <div class="col-md-4">
                <a href="https://advances.sciencemag.org/content/5/8/eaaw7416" target="_blank"><img class="img-fluid"
                    src="publications/2019/z2019sci.jpg" alt=""></a>
              </div>
              <div class="col-md-8 publication-text">
                <strong>Title:</strong> Artificial intelligence for art investigation: Meeting the challenge of
                separating x-ray images of the Ghent Altarpiece<br>
                <strong>Authors:</strong> Z. Sabetsarvestani, B. Sober, C. Higgitt, I. Daubechies, M. R. D.
                Rodrigues<br>
                <strong>Journal/Conference:</strong> Science Advances<br>
                <p> <strong>Abstract:</strong> X-ray images of polyptych wings, or other artworks painted on both sides
                  of their support, contain in one image content from both paintings, making them difficult for experts
                  to “read.” To improve the utility of these x-ray images in studying these artworks, it is desirable to
                  separate the content into two images, each pertaining to only one side. This is a difficult task for
                  which previous approaches have been only partially successful. Deep neural network algorithms have
                  recently achieved remarkable progress in a wide range of image analysis and other challenging tasks.
                  We, therefore, propose a new self-supervised approach to this x-ray separation, leveraging an
                  available convolutional neural network architecture; results obtained for details from the Adam and
                  Eve panels of the Ghent Altarpiece spectacularly improve on previous attempts.</p>
                <a href="https://advances.sciencemag.org/content/5/8/eaaw7416" target="_blank"><strong><i class="fas fa-link"></i> Link</strong></a>
              </div>
            </div>
          </div>
        </div>
        <div class="row">
          <div class="col-md-12">
            <div id="song2019ieee1" class="row publication">
              <div class="col-md-4">
                <a href="https://ieeexplore.ieee.org/abstract/document/8715417" target="_blank"><img class="img-fluid"
                    src="publications/2019/song2019ieee1.png" alt=""></a>
              </div>
              <div class="col-md-8 publication-text">
                <strong>Title:</strong> Multimodal Image Super-resolution via Joint Sparse Representations induced by
                Coupled Dictionaries<br>
                <strong>Authors:</strong> P. Song, X. Deng, J. F. C. Mota, N. Deligiannis, P.-L. Dragotti, and M. R. D.
                Rodrigues<br>
                <strong>Journal/Conference:</strong> IEEE Transactions on Computational Imaging<br>
                <p> <strong>Abstract:</strong> Real-world data processing problems often involve various image
                  modalities associated with a certain scene, including RGB images, infrared images or multi-spectral
                  images. The fact that different image modalities often share certain attributes, such as edges,
                  textures and other structure primitives, represents an opportunity to enhance various image processing
                  tasks. This paper proposes a new approach to construct a high-resolution (HR) version of a
                  low-resolution (LR) image given another HR image modality as guidance, based on joint sparse
                  representations induced by coupled dictionaries. The proposed approach captures complex dependency
                  correlations, including similarities and disparities, between different image modalities in a learned
                  sparse feature domain in lieu of the original image domain. It consists of two phases: coupled
                  dictionary learning phase and coupled super-resolution phase. The learning phase learns a set of
                  dictionaries from the training dataset to couple different image modalities together in the sparse
                  feature domain. In turn, the super-resolution phase leverages such dictionaries to construct a HR
                  version of the LR target image with another related image modality for guidance. In the advanced
                  version of our approach, multi-stage strategy and neighbourhood regression concept are introduced to
                  further improve the model capacity and performance. Extensive guided image super-resolution
                  experiments on real multimodal images demonstrate that the proposed approach admits distinctive
                  advantages with respect to the state-of-the-art approaches, for example, overcoming the texture
                  copying artifacts commonly resulting from inconsistency between the guidance and target images. Of
                  particular relevance, the proposed model demonstrates much better robustness than competing deep
                  models in a range of noisy scenarios.</p>
                <a href="https://ieeexplore.ieee.org/abstract/document/8715417"
                  target="_blank"><strong><i class="fas fa-link"></i> Link</strong></a>
              </div>
            </div>
          </div>
        </div>
        <div class="row">
          <div class="col-md-12">
            <div id="deng2019ieee" class="row publication">
              <div class="col-md-4">
                <a href="https://ieeexplore.ieee.org/abstract/document/8741062" target="_blank"><img class="img-fluid"
                    src="publications/2019/deng2019ieee.png" alt=""></a>
              </div>
              <div class="col-md-8 publication-text">
                <strong>Title:</strong> RADAR: Robust Algorithm for Depth Image Super Resolution Based on FRI Theory and
                Multimodal Dictionary Learning<br>
                <strong>Authors:</strong> X. Deng, P. Song, M. R. D. Rodrigues, and P.-L. Dragotti<br>
                <strong>Journal/Conference:</strong> IEEE Transactions on Circuits and Systems for Video Technology<br>
                <p> <strong>Abstract:</strong> Depth image super-resolution is a challenging problem, since normally
                  high upscaling factors are required (e.g., 16×), and depth images are often noisy. In order to achieve
                  large upscaling factors and resilience to noise, we propose a Robust Algorithm for Depth imAge super
                  Resolution (RADAR) that combines the power of finite rate of innovation (FRI) theory with multimodal
                  dictionary learning. Given a low-resolution (LR) depth image, we first model its rows and columns as
                  piece-wise polynomials and propose a FRI-based depth upscaling (FDU) algorithm to super-resolve the
                  image. Then, the upscaled moderate quality (MQ) depth image is further enhanced with the guidance of a
                  registered high-resolution (HR) intensity image. This is achieved by learning multimodal mappings from
                  the joint MQ depth and HR intensity pairs to the HR depth, through a recently proposed triple
                  dictionary learning (TDL) algorithm. Moreover, to speed up the super-resolution process, we introduce
                  a new projection-based rapid upscaling (PRU) technique that pre-calculates the projections from the
                  joint MQ depth and HR intensity pairs to the HR depth. Compared with state-of-the-art deep learning
                  based methods, our approach has two distinct advantages: we need a fraction of training data but can
                  achieve the best performance, and we are resilient to mismatches between training and testing
                  datasets. Extensive numerical results show that the proposed method outperforms other state-of-the-art
                  methods on either noise-free or noisy datasets with large upscaling factors up to 16× and can handle
                  unknown blurring kernels well.</p>
                <a href="https://ieeexplore.ieee.org/abstract/document/8741062"
                  target="_blank"><strong><i class="fas fa-link"></i> Link</strong></a>
              </div>
            </div>
          </div>
        </div>
        <div class="row">
          <div class="col-md-12">
            <div id="shlezinger2019ieee" class="row publication">
              <div class="col-md-4">
                <a href="https://arxiv.org/abs/1811.10077" target="_blank"><img class="img-fluid"
                    src="publications/2019/shlezinger2019ieee1.png" alt=""></a>
              </div>
              <div class="col-md-8 publication-text">
                <strong>Title:</strong> Asymptotic Task-Based Quantization with Application to Massive MIMO<br>
                <strong>Authors:</strong> N. Shlezinger, Y. C. Eldar, and M. R. D. Rodrigues<br>
                <strong>Journal/Conference:</strong> IEEE Transactions on Signal Processing<br>
                <p> <strong>Abstract:</strong> Quantizers take part in nearly every digital signal
                  processing system which operates on physical signals. They are
                  commonly designed to accurately represent the underlying signal,
                  regardless of the specific task to be performed on the quantized
                  data. In systems working with high-dimensional signals, such
                  as massive multiple-input multiple-output (MIMO) systems, it is
                  beneficial to utilize low-resolution quantizers, due to cost, power,
                  and memory constraints. In this work we study quantization of
                  high-dimensional inputs, aiming at improving performance under
                  resolution constraints by accounting for the system task in the
                  quantizers design. We focus on the task of recovering a desired signal statistically related to the
                  high-dimensional input, and analyze
                  two quantization approaches: We first consider vector quantization, which is typically computationally
                  infeasible, and characterize
                  the optimal performance achievable with this approach. Next, we
                  focus on practical systems which utilize hardware-limited scalar
                  uniform analog-to-digital converters (ADCs), and design a taskbased quantizer under this model. The
                  resulting system accounts
                  for the task by linearly combining the observed signal into a lower
                  dimension prior to quantization. We then apply our proposed
                  technique to channel estimation in massive MIMO networks. Our
                  results demonstrate that a system utilizing low-resolution scalar
                  ADCs can approach the optimal channel estimation performance
                  by properly accounting for the task in the system design.</p>
                <a href="https://arxiv.org/abs/1811.10077" target="_blank"><strong><i class="fas fa-link"></i> Link</strong></a>
              </div>
            </div>
          </div>
        </div>
        <div class="row">
          <div class="col-md-12">
            <div id="shlezinger2019ieee" class="row publication">
              <div class="col-md-4">
                <a href="https://arxiv.org/abs/1807.08305" target="_blank"><img class="img-fluid"
                    src="publications/2019/shlezinger2019ieee2.png" alt=""></a>
              </div>
              <div class="col-md-8 publication-text">
                <strong>Title:</strong> Hardware-Limited Task-Based Quantization<br>
                <strong>Authors:</strong> N. Shlezinger, Y. C. Eldar, and M. R. D. Rodrigues<br>
                <strong>Journal/Conference:</strong> IEEE Transactions on Signal Processing<br>
                <p> <strong>Abstract:</strong> Quantization plays a critical role in digital signal processing systems.
                  Quantizers are typically
                  designed to obtain an accurate digital representation of the input signal, operating independently of
                  the system task, and are commonly implemented using serial scalar analog-to-digital converters (ADCs).
                  In this work, we study hardware-limited task-based quantization, where a system utilizing a serial
                  scalar
                  ADC is designed to provide a suitable representation in order to allow the recovery of a parameter
                  vector
                  underlying the input signal. We propose hardware-limited task-based quantization systems for a fixed
                  and
                  finite quantization resolution, and characterize their achievable distortion. We then apply the
                  analysis to
                  the practical setups of channel estimation and eigen-spectrum recovery from quantized measurements.
                  Our
                  results illustrate that properly designed hardware-limited systems can approach the optimal
                  performance
                  achievable with vector quantizers, and that by taking the underlying task into account, the
                  quantization
                  error can be made negligible with a relatively small number of bits.</p>
                <a href="https://arxiv.org/abs/1807.08305" target="_blank"><strong><i class="fas fa-link"></i> Link</strong></a>
              </div>
            </div>
          </div>
        </div>
        <div class="row">
          <div class="col-md-12">
            <div id="song2019ieee2" class="row publication">
              <div class="col-md-4">
                <a href="https://ieeexplore.ieee.org/abstract/document/8786180" target="_blank"><img class="img-fluid"
                    src="publications/2019/song2019ieee2.png" alt=""></a>
              </div>
              <div class="col-md-8 publication-text">
                <strong>Title:</strong> Coupled Dictionary Learning for Multi-contrast MRI Reconstruction<br>
                <strong>Authors:</strong> P. Song, L. Weizmann, J. M. C. Mota, Y. Eldar, and M. R. D. Rodrigues<br>
                <strong>Journal/Conference:</strong> IEEE Transactions on Medical Imaging<br>
                <p> <strong>Abstract:</strong> Magnetic resonance (MR) imaging tasks often involve multiple contrasts,
                  such as T1-weighted, T2-weighted and Fluid-attenuated inversion recovery (FLAIR) data. These contrasts
                  capture information associated with the same underlying anatomy and thus exhibit similarities in
                  either structure level or gray level. In this paper, we propose a Coupled Dictionary Learning based
                  multi-contrast MRI reconstruction (CDLMRI) approach to leverage the dependency correlation between
                  different contrasts for guided or joint reconstruction from their under-sampled k-space data. Our
                  approach iterates between three stages: coupled dictionary learning, coupled sparse denoising, and
                  enforcing k-space consistency. The first stage learns a set of dictionaries that not only are adaptive
                  to the contrasts, but also capture correlations among multiple contrasts in a sparse transform domain.
                  By capitalizing on the learned dictionaries, the second stage performs coupled sparse coding to remove
                  the aliasing and noise in the corrupted contrasts. The third stage enforces consistency between the
                  denoised contrasts and the measurements in the k-space domain. Numerical experiments, consisting of
                  retrospective under-sampling of various MRI contrasts with a variety of sampling schemes, demonstrate
                  that CDLMRI is capable of capturing structural dependencies between different contrasts. The learned
                  priors indicate notable advantages in multi-contrast MR imaging and promising applications in
                  quantitative MR imaging such as MR fingerprinting.</p>
                <a href="https://ieeexplore.ieee.org/abstract/document/8786180"
                  target="_blank"><strong><i class="fas fa-link"></i> Link</strong></a>
              </div>
            </div>
          </div>
        </div>
        <div class="row">
          <div class="col-md-12">
            <div id="song2019med" class="row publication">
              <div class="col-md-12 publication-text">
                <strong>Title:</strong> HYDRA: Hybrid Deep Magnetic Resonance Fingerprinting<br>
                <strong>Authors:</strong> P. Song, G. Mazor, Y. C. Eldar, and M. R. D. Rodrigues<br>
                <strong>Journal/Conference:</strong> Medical Physics<br>
                <p> <strong>Abstract:</strong> PURPOSE:
                  Magnetic resonance fingerprinting (MRF) methods typically rely on dictionary matching to map the
                  temporal MRF signals to quantitative tissue parameters. Such approaches suffer from inherent
                  discretization errors, as well as high computational complexity as the dictionary size grows. To
                  alleviate these issues, we propose a HYbrid Deep magnetic ResonAnce fingerprinting (HYDRA) approach,
                  referred to as HYDRA.
                  <br>
                  METHODS:
                  HYDRA involves two stages: a model-based signature restoration phase and a learning-based parameter
                  restoration phase. Signal restoration is implemented using low-rank based de-aliasing techniques while
                  parameter restoration is performed using a deep nonlocal residual convolutional neural network. The
                  designed network is trained on synthesized MRF data simulated with the Bloch equations and fast
                  imaging with steady-state precession (FISP) sequences. In test mode, it takes a temporal MRF signal as
                  input and produces the corresponding tissue parameters.
                  <br>
                  RESULTS:
                  We validated our approach on both synthetic data and anatomical data generated from a healthy subject.
                  The results demonstrate that, in contrast to conventional dictionary matching-based MRF techniques,
                  our approach significantly improves inference speed by eliminating the time-consuming dictionary
                  matching operation, and alleviates discretization errors by outputting continuous-valued parameters.
                  We further avoid the need to store a large dictionary, thus reducing memory requirements.
                  <br>
                  CONCLUSIONS:
                  Our approach demonstrates advantages in terms of inference speed, accuracy, and storage requirements
                  over competing MRF methods.</p>
                <a href="https://www.ncbi.nlm.nih.gov/pubmed/31329307" target="_blank"><strong><i class="fas fa-link"></i> Link</strong></a>
              </div>
            </div>
          </div>
        </div>
        <div class="row">
          <div class="col-md-12">
            <div id="bertran2019icml" class="row publication">
              <div class="col-md-4">
                <a href="http://proceedings.mlr.press/v97/bertran19a.html" target="_blank"><img class="img-fluid"
                    src="publications/2019/bertran2019icml.png" alt=""></a>
              </div>
              <div class="col-md-8 publication-text">
                <strong>Title:</strong> Adversarially Learned Representations for Information Obfuscation and
                Inference<br>
                <strong>Authors:</strong> M. A. Bertran, N. Martinez, A. Papadaki, Q. Qiu, M. R. D. Rodrigues, G.
                Reeves, and G. Sapiro.<br>
                <strong>Journal/Conference:</strong> International Conference on Machine Learning (ICML)<br>
                <p> <strong>Abstract:</strong> Data collection and sharing are pervasive aspects of modern society. This
                  process can either be voluntary, as in the case of a person taking a facial image to unlock his/her
                  phone, or incidental, such as traffic cameras collecting videos on pedestrians. An undesirable side
                  effect of these processes is that shared data can carry information about attributes that users might
                  consider as sensitive, even when such information is of limited use for the task. It is therefore
                  desirable for both data collectors and users to design procedures that minimize sensitive information
                  leakage. Balancing the competing objectives of providing meaningful individualized service levels and
                  inference while obfuscating sensitive information is still an open problem. In this work, we take an
                  information theoretic approach that is implemented as an unconstrained adversarial game between Deep
                  Neural Networks in a principled, data-driven manner. This approach enables us to learn
                  domain-preserving stochastic transformations that maintain performance on existing algorithms while
                  minimizing sensitive information leakage.</p>
                <a href="http://proceedings.mlr.press/v97/bertran19a.html" target="_blank"><strong><i class="fas fa-link"></i> Link</strong></a>
              </div>
            </div>
          </div>
        </div>
        <div class="row">
          <div id="2018" class="col-md-12 mb-5">
            <h2>2018</h2>
            <hr>
          </div>
        </div>
        <div class="row">
          <div class="col-md-12">
            <div id="mrd2018" class="row publication">
              <div class="col-md-12 publication-text">
                <strong>Title:</strong> Introduction to the issue on information-theoretic methods in data acquisition,
                analysis, and processing<br>
                <strong>Authors:</strong> Rodrigues, M., Bolcskei, H., Draper, S., Eldar, Y., & Tan, V<br>
                <strong>Journal/Conference:</strong> IEEE Journal on Selected Topics in Signal Processing<br>
                <p> <strong>Abstract:</strong> The twenty papers that are included in this special section explore
                  applications of information theoretic methods to emerging data science problems. In particular, the
                  papers cover a wide range of topics that can broadly be organized into four themes: (1) data
                  acquisition, (2) data analysis and processing, (3) statistics and machine learning, and (4) privacy
                  and fairness.</p>
                <a href="https://ieeexplore.ieee.org/document/8476530" target="_blank"><strong><i class="fas fa-link"></i> Link</strong></a>
              </div>
            </div>
          </div>
        </div>
        <div class="row">
          <div class="col-md-12">
            <div id="chen2018ieee" class="row publication">
              <div class="col-md-4">
                <a href="https://ieeexplore.ieee.org/document/8301528" target="_blank"><img class="img-fluid"
                    src="publications/2018/chen2018ieee.png" alt=""></a>
              </div>
              <div class="col-md-8 publication-text">
                <strong>Title:</strong> Compressive Sensing With Side Information: How to Optimally Capture This Extra
                Information for GMM Signals?<br>
                <strong>Authors:</strong> Chen, M., Renna, F., & Rodrigues, M. R. D<br>
                <strong>Journal/Conference:</strong> IEEE Transactions on Signal Processing<br>
                <p> <strong>Abstract:</strong> This paper studies how to optimally capture side information to aid in
                  the reconstruction of high-dimensional signals from low-dimensional random linear and noisy
                  measurements, by assuming that both the signal of interest and the side information signal are drawn
                  from a joint Gaussian mixture model. In particular, we derive sufficient and (occasionally) necessary
                  conditions on the number of linear measurements for the signal reconstruction minimum mean squared
                  error (MMSE) to approach zero in the low-noise regime; moreover, we also derive closed-form linear
                  side information measurement designs for the reconstruction MMSE to approach zero in the low-noise
                  regime. Our designs suggest that a linear projection kernel that optimally captures side information
                  is such that it measures the attributes of side information that are maximally correlated with the
                  signal of interest. A number of experiments both with synthetic and real data confirm that our
                  theoretical results are well aligned with numerical ones. Finally, we offer a case study associated
                  with a panchromatic sharpening (pan sharpening) application in the presence of compressive
                  hyperspectral data that demonstrates that our proposed linear side information measurement designs can
                  lead to reconstruction peak signal-to-noise ratio (PSNR) gains in excess of 2 dB over other approaches
                  in this practical application.</p>
                <a href="https://ieeexplore.ieee.org/document/8301528" target="_blank"><strong><i class="fas fa-link"></i> Link</strong></a>
              </div>
            </div>
          </div>
        </div>
        <div class="row">
          <div id="2017" class="col-md-12 mb-5">
            <h2>2017</h2>
            <hr>
          </div>
        </div>
        <div class="row">
          <div class="col-md-12">
            <div id="deligiannis2017ieee" class="row publication">
              <div class="col-md-4">
                <a href="https://ieeexplore.ieee.org/abstract/document/8017563" target="_blank"><img class="img-fluid"
                    src="publications/2017/deligiannis2017ieee.png" alt=""></a>
              </div>
              <div class="col-md-8 publication-text">
                <strong>Title:</strong> Heterogeneous Networked Data Recovery from Compressive Measurements Using a
                Copula Prior<br>
                <strong>Authors:</strong> Deligiannis, N., Mota, J. F. C., Zimos, E., & Rodrigues, M. R. D<br>
                <strong>Journal/Conference:</strong> IEEE Transactions on Communications<br>
                <p> <strong>Abstract:</strong> Large-scale data collection by means of wireless sensor network and
                  Internet-of-Things technology poses various challenges in view of the limitations in transmission,
                  computation, and energy resources of the associated wireless devices. Compressive data gathering based
                  on compressed sensing has been proven a well-suited solution to the problem. Existing designs exploit
                  the spatiotemporal correlations among data collected by a specific sensing modality. However, many
                  applications, such as environmental monitoring, involve collecting heterogeneous data that are
                  intrinsically correlated. In this paper, we propose to leverage the correlation from multiple
                  heterogeneous signals when recovering the data from compressive measurements. To this end, we propose
                  a novel recovery algorithm-built upon belief-propagation principles-that leverages correlated
                  information from multiple heterogeneous signals. To efficiently capture the statistical dependencies
                  among diverse sensor data, the proposed algorithm uses the statistical model of copula functions.
                  Experiments with heterogeneous air-pollution sensor measurements show that the proposed design
                  provides significant performance improvements against the state-of-the-art compressive data gathering
                  and recovery schemes that use classical compressed sensing, compressed sensing with side information,
                  and distributed compressed sensing.</p>
                <a href="https://ieeexplore.ieee.org/abstract/document/8017563"
                  target="_blank"><strong><i class="fas fa-link"></i> Link</strong></a>
              </div>
            </div>
          </div>
        </div>
        <div class="row">
          <div class="col-md-12">
            <div id="sokolic2017ieee" class="row publication">
              <div class="col-md-4">
                <a href="https://arxiv.org/abs/1605.08254" target="_blank"><img class="img-fluid"
                    src="publications/2017/sokolic2017ieee.png" alt=""></a>
              </div>
              <div class="col-md-8 publication-text">
                <strong>Title:</strong> Robust Large Margin Deep Neural Networks<br>
                <strong>Authors:</strong> Sokolic, J., Giryes, R., Sapiro, G., & Rodrigues, M. R. D<br>
                <strong>Journal/Conference:</strong> IEEE Transactions on Signal Processing<br>
                <p> <strong>Abstract:</strong> The generalization error of deep neural networks via their classification
                  margin is studied in this work. Our approach is based on the Jacobian matrix of a deep neural network
                  and can be applied to networks with arbitrary non-linearities and pooling layers, and to networks with
                  different architectures such as feed forward networks and residual networks. Our analysis leads to the
                  conclusion that a bounded spectral norm of the network's Jacobian matrix in the neighbourhood of the
                  training samples is crucial for a deep neural network of arbitrary depth and width to generalize well.
                  This is a significant improvement over the current bounds in the literature, which imply that the
                  generalization error grows with either the width or the depth of the network. Moreover, it shows that
                  the recently proposed batch normalization and weight normalization re-parametrizations enjoy good
                  generalization properties, and leads to a novel network regularizer based on the network's Jacobian
                  matrix. The analysis is supported with experimental results on the MNIST, CIFAR-10, LaRED and ImageNet
                  datasets.</p>
                <a href="https://arxiv.org/abs/1605.08254" target="_blank"><strong><i class="fas fa-link"></i> Link</strong></a>
              </div>
            </div>
          </div>
        </div>
        <div class="row">
          <div class="col-md-12">
            <div id="mota2017ieee" class="row publication">
              <div class="col-md-4">
                <a href="https://ieeexplore.ieee.org/abstract/document/7904593" target="_blank"><img class="img-fluid"
                    src="publications/2017/mota2017ieee.png" alt=""></a>
              </div>
              <div class="col-md-8 publication-text">
                <strong>Title:</strong> Compressed Sensing With Prior Information: Strategies, Geometry, and Bounds<br>
                <strong>Authors:</strong> Mota, J. F. C., Deligiannis, N., & Rodrigues, M. R. D<br>
                <strong>Journal/Conference:</strong> IEEE Transactions on Information Theory<br>
                <p> <strong>Abstract:</strong> We address the problem of compressed sensing (CS) with prior
                  information: reconstruct a target CS signal with the aid of a similar signal that is known beforehand,
                  our prior information. We integrate the additional knowledge of the similar signal into CS via l 1 -l
                  1 and l 1 -l 2 minimization. We then establish bounds on the number of measurements required by these
                  problems to successfully reconstruct the original signal. Our bounds and geometrical interpretations
                  reveal that if the prior information has good enough quality, l 1 -l 1 minimization improves the
                  performance of CS dramatically. In contrast, l 1 -l 2 minimization has a performance very similar to
                  classical CS, and brings no significant benefits. In addition, we use the insight provided by our
                  bounds to design practical schemes to improve prior information. All our findings are illustrated with
                  experimental results.</p>
                <a href="https://ieeexplore.ieee.org/abstract/document/7904593"
                  target="_blank"><strong><i class="fas fa-link"></i> Link</strong></a>
              </div>
            </div>
          </div>
        </div>
        <div class="row">
          <div class="col-md-12">
            <div id="sokolic2017aistats" class="row publication">
              <div class="col-md-4">
                <a href="https://arxiv.org/abs/1610.04574" target="_blank"><img class="img-fluid"
                    src="publications/2017/sokolic2017aistats.png" alt=""></a>
              </div>
              <div class="col-md-8 publication-text">
                <strong>Title:</strong> Generalization Error of Invariant Classifiers<br>
                <strong>Authors:</strong> J. Sokolic, R. Gyries, G. Sapiro, and M. R. D. Rodrigue<br>
                <strong>Journal/Conference:</strong> Proceedings of the 20th International Conference on Artificial
                Intelligence and Statistics (AISTATS)<br>
                <p> <strong>Abstract:</strong> This paper studies the generalization error of invariant classifiers. In
                  particular, we consider the common scenario where the classification task is invariant to certain
                  transformations of the input, and that the classifier is constructed (or learned) to be invariant to
                  these transformations. Our approach relies on factoring the input space into a product of a base space
                  and a set of transformations. We show that whereas the generalization error of a non-invariant
                  classifier is proportional to the complexity of the input space, the generalization error of an
                  invariant classifier is proportional to the complexity of the base space. We also derive a set of
                  sufficient conditions on the geometry of the base space and the set of transformations that ensure
                  that the complexity of the base space is much smaller than the complexity of the input space. Our
                  analysis applies to general classifiers such as convolutional neural networks. We demonstrate the
                  implications of the developed theory for such classifiers with experiments on the MNIST and CIFAR-10
                  datasets.</p>
                <a href="https://arxiv.org/abs/1610.04574" target="_blank"><strong><i class="fas fa-link"></i> Link</strong></a>
              </div>
            </div>
          </div>
        </div>
        <div class="row">
          <div id="2016" class="col-md-12 mb-5">
            <h2>2016</h2>
            <hr>
          </div>
        </div>
        <div class="row">
          <div class="col-md-12">
            <div id="renna2016ieee" class="row publication">
              <div class="col-md-4">
                <a href="https://ieeexplore.ieee.org/document/7562475" target="_blank"><img class="img-fluid"
                    src="publications/2016/renna2016ieee.png" alt=""></a>
              </div>
              <div class="col-md-8 publication-text">
                <strong>Title:</strong> Classification and Reconstruction of High-Dimensional Signals From
                Low-Dimensional Features in the Presence of Side Information<br>
                <strong>Authors:</strong> Renna, F., Wang, L., Yuan, X., Yang, J., Reeves, G., Calderbank, R.,
                Rodrigues, M. R. D<br>
                <strong>Journal/Conference:</strong> IEEE Transactions on Information Theory<br>
                <p> <strong>Abstract:</strong> This paper offers a characterization of fundamental limits on the
                  classification and reconstruction of high-dimensional signals from low-dimensional features, in the
                  presence of side information. We consider a scenario where a decoder has access both to linear
                  features of the signal of interest and to linear features of the side information signal; while the
                  side information may be in a compressed form, the objective is recovery or classification of the
                  primary signal, not the side information. The signal of interest and the side information are each
                  assumed to have (distinct) latent discrete labels; conditioned on these two labels, the signal of
                  interest and side information are drawn from a multivariate Gaussian distribution that correlates the
                  two. With joint probabilities on the latent labels, the overall signal-(side information)
                  representation is defined by a Gaussian mixture model. By considering bounds to the misclassification
                  probability associated with the recovery of the underlying signal label, and bounds to the
                  reconstruction error associated with the recovery of the signal of interest itself, we then provide
                  sharp sufficient and/or necessary conditions for these quantities to approach zero when the covariance
                  matrices of the Gaussians are nearly low rank. These conditions, which are reminiscent of the
                  well-known Slepian-Wolf and Wyner-Ziv conditions, are the function of the number of linear features
                  extracted from signal of interest, the number of linear features extracted from the side information
                  signal, and the geometry of these signals and their interplay. Moreover, on assuming that the signal
                  of interest and the side information obey such an approximately low-rank model, we derive the
                  expansions of the reconstruction error as a function of the deviation from an exactly low-rank model;
                  such expansions also allow the identification of operational regimes, where the impact of side
                  information on signal reconstruction is most relevant. Our framework, which offers a principled
                  mechanism to integrate side information in high-dimensional data problems, is also tested in the
                  context of imaging applications. In particular, we report state-of-theart results in compressive
                  hyperspectral imaging applications, where the accompanying side information is a conventional digital
                  photograph.</p>
                <a href="https://ieeexplore.ieee.org/document/7562475" target="_blank"><strong><i class="fas fa-link"></i> Link</strong></a>
              </div>
            </div>
          </div>
        </div>
        <div class="row">
          <div class="col-md-12">
            <div id="deligiannis2016ieee" class="row publication">
              <div class="col-md-4">
                <a href="https://ieeexplore.ieee.org/document/7725950" target="_blank"><img class="img-fluid"
                    src="publications/2016/deligiannis2016ieee.png" alt=""></a>
              </div>
              <div class="col-md-8 publication-text">
                <strong>Title:</strong> Multi-Modal Dictionary Learning for Image Separation With Application In Art
                Investigation<br>
                <strong>Authors:</strong> Deligiannis, N., Mota, J. F. C., Cornelis, B., Rodrigues, M. R. D., &
                Daubechies, I.<br>
                <strong>Journal/Conference:</strong> IEEE Transactions on Image Processing<br>
                <p> <strong>Abstract:</strong> In support of art investigation, we propose a new source separation
                  method that unmixes a single X-ray scan acquired from double-sided paintings. In this problem, the
                  X-ray signals to be separated have similar morphological characteristics, which brings previous source
                  separation methods to their limits. Our solution is to use photographs taken from the front-and
                  back-side of the panel to drive the separation process. The crux of our approach relies on the
                  coupling of the two imaging modalities (photographs and X-rays) using a novel coupled dictionary
                  learning framework able to capture both common and disparate features across the modalities using
                  parsimonious representations; the common component captures features shared by the multi-modal images,
                  whereas the innovation component captures modality-specific information. As such, our model enables
                  the formulation of appropriately regularized convex optimization procedures that lead to the accurate
                  separation of the X-rays. Our dictionary learning framework can be tailored both to a single- and a
                  multi-scale framework, with the latter leading to a significant performance improvement. Moreover, to
                  improve further on the visual quality of the separated images, we propose to train coupled
                  dictionaries that ignore certain parts of the painting corresponding to craquelure. Experimentation on
                  synthetic and real data - taken from digital acquisition of the Ghent Altarpiece (1432) - confirms the
                  superiority of our method against the state-of-the-art morphological component analysis technique that
                  uses either fixed or trained dictionaries to perform image separation.</p>
                <a href="https://ieeexplore.ieee.org/document/7725950" target="_blank"><strong><i class="fas fa-link"></i> Link</strong></a>
              </div>
            </div>
          </div>
        </div>
        <div class="row">
          <div class="col-md-12">
            <div id="reboredo2016ieee" class="row publication">
              <div class="col-md-4">
                <a href="https://ieeexplore.ieee.org/document/7542135" target="_blank"><img class="img-fluid"
                    src="publications/2016/reboredo2016ieee.png" alt=""></a>
              </div>
              <div class="col-md-8 publication-text">
                <strong>Title:</strong> Bounds on the Number of Measurements for Reliable Compressive Classification<br>
                <strong>Authors:</strong> Reboredo, H., Renna, F., Calderbank, R., & Rodrigues, M. R. D<br>
                <strong>Journal/Conference:</strong> IEEE Transactions on Signal Processing<br>
                <p> <strong>Abstract:</strong> This paper studies the classification of high-dimensional Gaussian
                  signals from low-dimensional noisy, linear measurements. In particular, it provides upper bounds
                  (sufficient conditions) on the number of measurements required to drive the probability of
                  misclassification to zero in the low-noise regime, both for random measurements and designed ones.
                  Such bounds reveal two important operational regimes that are a function of the characteristics of the
                  source: 1) when the number of classes is less than or equal to the dimension of the space spanned by
                  signals in each class, reliable classification is possible in the low-noise regime by using a
                  one-vs-all measurement design; 2) when the dimension of the spaces spanned by signals in each class is
                  lower than the number of classes, reliable classification is guaranteed in the low-noise regime by
                  using a simple random measurement design. Simulation results both with synthetic and real data show
                  that our analysis is sharp, in the sense that it is able to gauge the number of measurements required
                  to drive the misclassification probability to zero in the low-noise regime.</p>
                <a href="https://ieeexplore.ieee.org/document/7542135" target="_blank"><strong><i class="fas fa-link"></i> Link</strong></a>
              </div>
            </div>
          </div>
        </div>
        <div class="row">
          <div class="col-md-12">
            <div id="mota2016ieee" class="row publication">
              <div class="col-md-4">
                <a href="https://ieeexplore.ieee.org/document/7442140" target="_blank"><img class="img-fluid"
                    src="publications/2016/mota2016ieee.png" alt=""></a>
              </div>
              <div class="col-md-8 publication-text">
                <strong>Title:</strong> Adaptive-Rate Reconstruction of Time-Varying Signals With Application in
                Compressive Foreground Extraction<br>
                <strong>Authors:</strong> Mota, J. F. C., Deligiannis, N., Sankaranarayanan, A. C., Cevher, V., &
                Rodrigues, M. R. D. <br>
                <strong>Journal/Conference:</strong> IEEE Transactions on Signal Processing<br>
                <p> <strong>Abstract:</strong> We propose and analyze an online algorithm for reconstructing a sequence
                  of signals from a limited number of linear measurements. The signals are assumed sparse, with unknown
                  support, and evolve over time according to a generic nonlinear dynamical model. Our algorithm, based
                  on recent theoretical results for l1 - l1 minimization, is recursive and computes the number of
                  measurements to be taken at each time on-the-fly. As an example, we apply the algorithm to online
                  compressive video foreground extraction, a problem stated as follows: given a set of measurements of a
                  sequence of images with a static background, simultaneously reconstruct each image while separating
                  its foreground from the background. The performance of our method is illustrated on sequences of real
                  images. We observe that it allows a dramatic reduction in the number of measurements or reconstruction
                  error with respect to state-of-the-art compressive background subtraction schemes.</p>
                <a href="https://ieeexplore.ieee.org/document/7442140" target="_blank"><strong><i class="fas fa-link"></i> Link</strong></a>
              </div>
            </div>
          </div>
        </div>
        <div class="row">
          <div class="col-md-12">
            <div id="wang2016ieee" class="row publication">
              <div class="col-md-4">
                <a href="https://ieeexplore.ieee.org/abstract/document/7469791" target="_blank"><img class="img-fluid"
                    src="publications/2016/wang2016ieee.png" alt=""></a>
              </div>
              <div class="col-md-8 publication-text">
                <strong>Title:</strong> Information-Theoretic Compressive Measurement Design<br>
                <strong>Authors:</strong> Wang, L., Chen, M., Rodrigues, M., Wilcox, D., Calderbank, R., & Carin, L.
                <br>
                <strong>Journal/Conference:</strong> IEEE Transactions on Pattern Analysis and Machine Intelligence<br>
                <p> <strong>Abstract:</strong> An information-theoretic projection design framework is proposed, of
                  interest for feature design and compressive measurements. Both Gaussian and Poisson measurement models
                  are considered. The gradient of a proposed information-theoretic metric (ITM) is derived, and a
                  gradient-descent algorithm is applied in design; connections are made to the information bottleneck.
                  The fundamental solution structure of such design is revealed in the case of a Gaussian measurement
                  model and arbitrary input statistics. This new theoretical result reveals how ITM parameter settings
                  impact the number of needed projection measurements, with this verified experimentally. The ITM
                  achieves promising results on real data, for both signal recovery and classification.</p>
                <a href="https://ieeexplore.ieee.org/abstract/document/7469791"
                  target="_blank"><strong><i class="fas fa-link"></i> Link</strong></a>
              </div>
            </div>
          </div>
        </div>
        <div class="row">
          <div class="col-md-12">
            <div id="sokolic2016ieee" class="row publication">
              <div class="col-md-4">
                <a href="https://ieeexplore.ieee.org/document/7423815" target="_blank"><img class="img-fluid"
                    src="publications/2016/sokolic2016ieee.png" alt=""></a>
              </div>
              <div class="col-md-8 publication-text">
                <strong>Title:</strong> Mismatch in the Classification of Linear Subspaces: Sufficient Conditions for
                Reliable Classification<br>
                <strong>Authors:</strong> Sokolic, J., Renna, F., Calderbank, R., & Rodrigues, M. R. D
                <br>
                <strong>Journal/Conference:</strong> IEEE Transactions on Signal Processing<br>
                <p> <strong>Abstract:</strong> This paper considers the classification of linear subspaces with
                  mismatched classifiers. In particular, we assume a model where one observes signals in the presence of
                  isotropic Gaussian noise and the distribution of the signals conditioned on a given class is Gaussian
                  with a zero mean and a low-rank covariance matrix. We also assume that the classifier knows only a
                  mismatched version of the parameters of input distribution in lieu of the true parameters. By
                  constructing an asymptotic low-noise expansion of an upper bound to the error probability of such a
                  mismatched classifier, we provide sufficient conditions for reliable classification in the low-noise
                  regime that are able to sharply predict the absence of a classification error floor. Such conditions
                  are a function of the geometry of the true signal distribution, the geometry of the mismatched signal
                  distributions as well as the interplay between such geometries, namely, the principal angles and the
                  overlap between the true and the mismatched signal subspaces. Numerical results demonstrate that our
                  conditions for reliable classification can sharply predict the behavior of a mismatched classifier
                  both with synthetic data and in a motion segmentation and a hand-written digit classification
                  applications.</p>
                <a href="https://ieeexplore.ieee.org/document/7423815" target="_blank"><strong><i class="fas fa-link"></i> Link</strong></a>
              </div>
            </div>
          </div>
        </div>
        <div class="row">
          <div class="col-md-12">
            <div id="sokolic2016iclr" class="row publication">
              <div class="col-md-4">
                <a href="http://discovery.ucl.ac.uk/10063246/" target="_blank"><img class="img-fluid"
                    src="publications/2016/sokolic2016iclr.png" alt=""></a>
              </div>
              <div class="col-md-8 publication-text">
                <strong>Title:</strong> Lessons from the Rademacher complexity for deep learning<br>
                <strong>Authors:</strong> Sokolic, J., Gyries, R., Sapiro, G., & Rodrigues, M. R. D.
                <br>
                <strong>Journal/Conference:</strong> International Conference on Learning Representations (ICLR)<br>
                <p> <strong>Abstract:</strong> Understanding the generalization properties of deep learning models is
                  critical for successful applications, especially in the regimes where the number of training samples
                  is limited. We study the generalization properties of deep neural networks via the empirical
                  Rademacher complexity and show that it is easier to control the complexity of convolutional networks
                  compared to general fully connected networks. In particular, we justify the usage of small
                  convolutional kernels in deep networks as they lead to a better generalization error. Moreover, we
                  propose a representation based regularization method that allows to decrease the generalization error
                  by controlling the coherence of the representation. Experiments on the MNIST dataset support these
                  foundations.</p>
                <a href="http://discovery.ucl.ac.uk/10063246/" target="_blank"><strong><i class="fas fa-link"></i> Link</strong></a>
              </div>
            </div>
          </div>
        </div>
        <div class="row">
          <div id="Older" class="col-md-12 mb-5">
            <h2>Older Papers</h2>
            <hr>
          </div>
        </div>
      </div>
    </div>
  </div>
  <!-- /.container -->

  <!-- Footer -->
  <div id="footer">

  </div>



</body>

</html>